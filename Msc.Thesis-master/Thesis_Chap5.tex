\chapter{آزمایش و نتایج}\label{Chap5}
\minitoc

پس از تقسیم‌بندی مسئله به زیرمسائل مختلف و ارائه دادن مدل‌های پیشنهادی برای هر یک از زیر مسائل در فصل پیش، در این فصل نتایج پیاده‌سازی و آموزش مدل‌ها ارائه خواهد شد و در مورد مقایسه آن‌ها با یکدیگر و نتایجشان نیز بحث صورت خواهد گرفت. در ضمن از آن‌جایی که مدل پیشنهاد شده برای گپ‌زن، یک مدل چند بخشی است، ارزیابی گپ‌زن در سه بخش مجزا انجام خواهد شد. در واقع در دو زیر مساله انتخاب دانش و تولید پاسخ ارزیابی گپ‌زن به صورت جزیی و در بخش سوم نیز ارزیابی کلی سامانه گپ‌زن (با توجه به احتمال انتشار خطا از مرحله‌ای به مراحل بعدی) صورت خواهد پذیرفت.

\section{محیط آزمایش و ابزارها}

پیاده‌سازی مدل‌های این پژوهش و آموزش‌‌ ‌آن‌ها با استفاده از 
\trans{چارچوب}{Framework}
\trans{پایتورچ}{Pytorch}
که مبتنی بر زبان
\trans{پایتون}{Python}
است صورت گرفته است. همچنان جهت بارگیری‌کردن و استفاده از مدل‌های از پیش آموزش دیده شده نیز از کتابخانه ارزشمند 
\lr{HuggingFace}
بهره برده شده است. 

آموزش و تنظیم‌ مدل‌های این پژوهش نیز همگی با استفاده از سرویس 
\lr{Google Colab}
انجام گرفته‌اند. از آنجایی که حجم دادگان این پژوهش بعضا بسیار فراتر از آن است که بتوان در چند ساعت بر روی آن‌ها یکبار عمل آموزش شبکه را انجام داد و هم این که سرویس 
\lr{Colab}
پس از هر ۹ ساعت عملیات قبلی را متوقف می‌کند،‌ ترتیبی در پیاده‌سازی مکانیزم آموزش مدل‌ها اندیشیده شده است که مشخصات محیط آزمایش و دادگانی که مورد آموزش واقع ‌شده‌اند حفظ و بتوانند بازیابی شوند تا همه دادگان سهم یکسانی در آموزش مدل داشته باشند. 



\section{ارزیابی مدل انتخاب دانش}
\subsection{مقدمه}
در این بخش توضیحات و نتایج مربوط به پیاده‌سازی مدل‌های پیشنهاد شده انتخاب دانش آورده شده‌اند. قبل از ذکر این نتایج لازم است تا توضیحی در مورد نحوه آموزش مدل‌ها و پیش‌پردازش‌های انجام داده و بهینه‌سازهای استفاده شده، آورده شود.

 ابتدا جهت آموزش مدل انتخاب دانش،‌ جفت دنباله‌هایی که به منظور محاسبه 
 \lr{true similarity}
 و
 \lr{false similarity}
 در بخش 
 \ref{chap4:solution:recom}
 مطرح شدند، بایستی استخراج شوند. بدین منظور تمامی جملات دانشی که بخش بازیابی اطلاعات در هنگام جمع آوری دادگان به عامل انسانی پیشنهاد داده و همچنین جمله دانشی که عامل انسانی از آن استفاده کرده جمع آوری می‌شوند. در صورتی که عامل انسانی از جمله‌ای استفاده نکرده باشد،‌ جمله دانش آن را رشته خالی در نظر می‌گیریم. حال به ازای هر نوبت از مکالمه زوج‌های جمله دانش درست و جمله دانش نامزد ، گردآوری می‌شوند. در نهایت محصول این مراحل 2775678 نمونه هستند که هر نمونه شامل دو زوج (تاریخچه گفتگو و جمله دانش صحیح) و (تاریخچه گفتگو و جمله دانش ناصحیح) است. 
 

از آن‌جایی که اولا مدل برت تنها می‌تواند دنباله‌هایی با طول حداکثر ۵۱۲ توکن را پردازش کند و ثانیا در صورت استفاده از دنباله‌های بلند در فرآیند یادگیری، با مشکل کمبود حافظه در سخت افزار مواجه می‌شویم، لذا لازم است تا مکانیزمی جهت کوتاه کردن دنباله ورودی به شبکه برت طراحی و اعمال شود. در این مکانیزم حداکثر طول دنباله ورودی به شبکه برت ۱۲۸ توکن فرض می‌شود و در صورتی که مجموع طول دنباله‌های تاریخچه گفتگو و جمله دانش بیشتر از این مقدار باشند، بایستی این دنباله‌ها کوتاه شوند. به این منظور دو دنباله تاریخچه و جمله دانش در نظر گرفته می‌شوند و هر بار از بلندترین آن‌ها یک توکن بریده می‌شود. اعمال بریدن توکن بر روی دنباله تاریخچه از سمت چپ و بر روی جمله دانش از سمت راست اعمال می‌شود. در نهایت حاصل از این مرحله دنباله‌های ورودی است که حداکثر ۱۲۸ توکن دارند. 

سپس دادگان تحت عمل دسته‌بندی به دسته‌های ۱۲۸تایی تقسیم می‌شوند و به شبکه به عنوان ورودی داده می‌شوند. برای بهینه‌سازی شبکه نیز از بهینه‌ساز آدام
\footnote{Adam}
با ترخ یادگیری ثابت 
$2e^{-5}$
استفاده می‌شود.

برای ارزیابی مدل‌های این بخش از دو معیار امتیاز
\lr{f1}
بین جمله انتخاب شده و جمله صحیح
و نرخ‌های 
\lr{Recall@1} و \lr{Recall@3} و \lr{Recall@5}
استفاده می‌شود. امتیاز
\lr{Recall@i}
در واقع نشان می‌دهد که در صورتی که مدل هر بار 
\lr{i}
جمله  با بیشترین امتیاز تخمین زده توسط خود را به عنوان نامزد‌های جمله دانش برگرداند، در چند درصد این موارد، جمله دانش صحیح در بین این 
\lr{i}
جمله خروجی قرار دارد. 



\section{ارزیابی مدل تولید پاسخ}


\section{ارزیابی کلی گپ‌زن}