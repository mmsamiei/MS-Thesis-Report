\chapter{آزمایش و نتایج}\label{Chap5}
\minitoc

پس از تقسیم‌بندی مسئله به زیرمسائل مختلف و ارائه دادن مدل‌های پیشنهادی برای هر یک از زیر مسائل در فصل پیش، در این فصل نتایج پیاده‌سازی و آموزش مدل‌ها ارائه خواهد شد و در مورد مقایسه آن‌ها با یکدیگر و نتایجشان نیز بحث صورت خواهد گرفت. در ضمن از آن‌جایی که مدل پیشنهاد شده برای گپ‌زن، یک مدل چند بخشی است، ارزیابی گپ‌زن در سه بخش مجزا انجام خواهد شد. در واقع در دو زیر مساله انتخاب دانش و تولید پاسخ ارزیابی گپ‌زن به صورت جزیی و در بخش سوم نیز ارزیابی کلی سامانه گپ‌زن (با توجه به احتمال انتشار خطا از مرحله‌ای به مراحل بعدی) صورت خواهد پذیرفت.

\section{محیط آزمایش و ابزارها}

پیاده‌سازی مدل‌های این پژوهش و آموزش‌‌ ‌آن‌ها با استفاده از 
\trans{چارچوب}{Framework}
\trans{پایتورچ}{Pytorch}
که مبتنی بر زبان
\trans{پایتون}{Python}
است صورت گرفته است. همچنان جهت بارگیری‌کردن و استفاده از مدل‌های از پیش آموزش دیده شده نیز از کتابخانه ارزشمند 
\lr{HuggingFace}
بهره برده شده است. 

آموزش و تنظیم‌ مدل‌های این پژوهش نیز همگی با استفاده از سرویس 
\lr{Google Colab}
انجام گرفته‌اند. از آنجایی که حجم دادگان این پژوهش بعضا بسیار فراتر از آن است که بتوان در چند ساعت بر روی آن‌ها یکبار عمل آموزش شبکه را انجام داد و هم این که سرویس 
\lr{Colab}
پس از هر ۹ ساعت عملیات قبلی را متوقف می‌کند،‌ ترتیبی در پیاده‌سازی مکانیزم آموزش مدل‌ها اندیشیده شده است که مشخصات محیط آزمایش و دادگانی که مورد آموزش واقع ‌شده‌اند حفظ و بتوانند بازیابی شوند تا همه دادگان سهم یکسانی در آموزش مدل داشته باشند. 



\section{ارزیابی مدل انتخاب دانش}
\subsection{مقدمه}
در این بخش توضیحات و نتایج مربوط به پیاده‌سازی مدل‌های پیشنهاد شده انتخاب دانش آورده شده‌اند. قبل از ذکر این نتایج لازم است تا توضیحی در مورد نحوه آموزش مدل‌ها و پیش‌پردازش‌های انجام داده و بهینه‌سازهای استفاده شده، آورده شود.

 ابتدا جهت آموزش مدل انتخاب دانش،‌ جفت دنباله‌هایی که به منظور محاسبه 
 \lr{true similarity}
 و
 \lr{false similarity}
 در بخش 
 \ref{chap4:solution:recom}
 مطرح شدند، بایستی استخراج شوند. بدین منظور تمامی جملات دانشی که بخش بازیابی اطلاعات در هنگام جمع آوری دادگان به عامل انسانی پیشنهاد داده و همچنین جمله دانشی که عامل انسانی از آن استفاده کرده جمع آوری می‌شوند. در صورتی که عامل انسانی از جمله‌ای استفاده نکرده باشد،‌ جمله دانش آن را رشته خالی در نظر می‌گیریم. حال به ازای هر نوبت از مکالمه زوج‌های جمله دانش درست و جمله دانش نامزد ، گردآوری می‌شوند. در نهایت محصول این مراحل 2775678 نمونه هستند که هر نمونه شامل دو زوج (تاریخچه گفتگو و جمله دانش صحیح) و (تاریخچه گفتگو و جمله دانش ناصحیح) است. 
 

از آن‌جایی که اولا مدل برت تنها می‌تواند دنباله‌هایی با طول حداکثر ۵۱۲ توکن را پردازش کند و ثانیا در صورت استفاده از دنباله‌های بلند در فرآیند یادگیری، با مشکل کمبود حافظه در سخت افزار مواجه می‌شویم، لذا لازم است تا مکانیزمی جهت کوتاه کردن دنباله ورودی به شبکه برت طراحی و اعمال شود. در این مکانیزم حداکثر طول دنباله ورودی به شبکه برت ۱۲۸ توکن فرض می‌شود و در صورتی که مجموع طول دنباله‌های تاریخچه گفتگو و جمله دانش بیشتر از این مقدار باشند، بایستی این دنباله‌ها کوتاه شوند. به این منظور دو دنباله تاریخچه و جمله دانش در نظر گرفته می‌شوند و هر بار از بلندترین آن‌ها یک توکن بریده می‌شود. اعمال بریدن توکن بر روی دنباله تاریخچه از سمت چپ و بر روی جمله دانش از سمت راست اعمال می‌شود. در نهایت حاصل از این مرحله دنباله‌های ورودی است که حداکثر ۱۲۸ توکن دارند. 

سپس دادگان تحت عمل دسته‌بندی به دسته‌های ۱۲۸تایی تقسیم می‌شوند و به شبکه به عنوان ورودی داده می‌شوند. برای بهینه‌سازی شبکه نیز از بهینه‌ساز آدام
\footnote{Adam}
با ترخ یادگیری ثابت 
$2e^{-5}$
استفاده می‌شود.

برای ارزیابی مدل‌های این بخش از دو معیار امتیاز
\lr{f1}
بین جمله انتخاب شده و جمله صحیح
و نرخ‌های 
\lr{Recall@1} و \lr{Recall@3} و \lr{Recall@5}
استفاده می‌شود. امتیاز
\lr{Recall@i}
در واقع نشان می‌دهد که در صورتی که مدل هر بار 
\lr{i}
جمله  با بیشترین امتیاز تخمین زده توسط خود را به عنوان نامزد‌های جمله دانش برگرداند، در چند درصد این موارد، جمله دانش صحیح در بین این 
\lr{i}
جمله خروجی قرار دارد. 
به علاوه امتیازی تحت عنوان نرخ برد دوتایی درست نیز ارائه خواهند که نشان می‌دهند مدل در چند مورد از نمونه‌های جفت جمله دانش صحیح و جمله دانش ناصحیح توانسته به جمله دانش صحیح امتیاز بالاتری دهد. 
از طرف از آن‌ جایی که دادگان تست جادوگر ویکی پدیا در دو قالب دادگان تست با موضوع آشنا و دادگان تست با موضوع ناآشنا عرضه شده‌اند، امتیاز مدل‌ها بر روی هر دوی این دادگان سنجیده می‌شود تا قدرت تعمیم‌دهی آن‌ها نسبت به موضوعات متفاوت نیز ارزیابی شود.  

هر یک از مدل‌ها یک 
\trans{دور}{Epoch}
معادل با بیش از بیست هزار گام روی دادگان آموزشی، آموزش می‌یابند.

\subsection{ارزیابی مدل انتخاب دانش مبتنی بر تابع هزینه‌ی لگاریتمی }
در این بخش مدل‌ پیشنهاد شده با تابع هزینه ارائه شده در بخش 
\ref{eq:log_loss_function}
آموزش یافته و نتایج عملکرد آن استخراج شده است. نتایج عملکرد این مدل‌ها بر روی دادگان تست با موضوع آشنا و موضوع ناآشنا در جدول‌های 
\ref{table:knowledge:log:unseen}
و 
\ref{table:knowledge:log:seen}
آمده است. تنظیمات و معماری این مدل‌ها نیز (تعداد لایه و اندازه حالت نهان) در ستون نام مدل آورده شده است.
\footnote{برای مثال مدل دو لایه با اندازه نهان ۱۲۸، به مدلی اشاره می‌کند که نقطه شروع اولیه آن برت مینیاتوری با ۲ لایه و اندازه نهان ۱۲۸ است.}

\begin{table}[h]
	\caption{نتایج بر روی دادگان آشنا مدل‌های انتخاب دانش با آموزش روی تابع خطای لگاریتمی }
	\centering
	\label{table:knowledge:log:seen}
	\begin{tabular}{|l|l|l|l|l|l|}
		\hline
		نام مدل                      & نرخ برد & R@1  & R@3    & R@5   & f1  \\ \hline
		مدل پایه جادوگر ویکی‌پدیا    & 23      & 1231 & 12.132 & 12.34 & 123 \\ \hline
		دو لایه با اندازه نهان ۱۲۸   & 123     &      & 123    &       & 13  \\ \hline
		چهار لایه با اندازه نهان ۲۵۶ &         &      &        & 132   & 123 \\ \hline
		چهار لایه با اندازه نهان ۵۱۲ &         & 132  &        &       & 132 \\ \hline
		شش لایه با اندازه نهان ۲۵۶   &         &      &        &       & 132 \\ \hline
	\end{tabular}
\end{table}

\begin{table}[h]
	\caption{نتایج بر روی دادگان ناآشنا مدل‌های انتخاب دانش با آموزش روی تابع خطای لگاریتمی }
	\centering
	\label{table:knowledge:log:unseen}
	\begin{tabular}{|l|l|l|l|l|l|}
		\hline
		نام مدل                      & نرخ برد & R@1  & R@3    & R@5   & f1  \\ \hline
		مدل پایه جادوگر ویکی‌پدیا    & 23      & 1231 & 12.132 & 12.34 & 123 \\ \hline
		دو لایه با اندازه نهان ۱۲۸   & 123     &      & 123    &       & 13  \\ \hline
		چهار لایه با اندازه نهان ۲۵۶ &         &      &        & 132   & 123 \\ \hline
		چهار لایه با اندازه نهان ۵۱۲ &         & 132  &        &       & 132 \\ \hline
		شش لایه با اندازه نهان ۲۵۶   &         &      &        &       & 132 \\ \hline
	\end{tabular}
\end{table}


\subsection{ارزیابی مدل انتخاب دانش مبتنی بر تابع هزینه خطی}

در این بخش مدل‌ پیشنهاد شده با تابع هزینه ارائه شده در بخش 
\ref{eq:linear_loss_function}
آموزش یافته و نتایج عملکرد آن استخراج شده است. نتایج عملکرد این مدل‌ها بر روی دادگان تست با موضوع آشنا و موضوع ناآشنا در جدول‌های 
\ref{table:knowledge:lin:unseen}
و 
\ref{table:knowledge:lin:seen}
آمده است.

\begin{table}[h]
	\caption{نتایج بر روی دادگان آشنا مدل‌های انتخاب دانش با آموزش روی تابع خطای خطی }
	\centering
	\label{table:knowledge:lin:seen}
	\begin{tabular}{|l|l|l|l|l|l|}
		\hline
		نام مدل                      & نرخ برد & R@1  & R@3    & R@5   & f1  \\ \hline
		مدل پایه جادوگر ویکی‌پدیا    & 23      & 1231 & 12.132 & 12.34 & 123 \\ \hline
		دو لایه با اندازه نهان ۱۲۸   & 123     &      & 123    &       & 13  \\ \hline
		چهار لایه با اندازه نهان ۲۵۶ &         &      &        & 132   & 123 \\ \hline
		چهار لایه با اندازه نهان ۵۱۲ &         & 132  &        &       & 132 \\ \hline
		شش لایه با اندازه نهان ۲۵۶   &         &      &        &       & 132 \\ \hline
	\end{tabular}
\end{table}

\begin{table}[h]
	\caption{نتایج بر روی دادگان ناآشنا مدل‌های انتخاب دانش با آموزش روی تابع خطای خطی }
	\centering
	\label{table:knowledge:lin:unseen}
	\begin{tabular}{|l|l|l|l|l|l|}
		\hline
		نام مدل                      & نرخ برد & R@1  & R@3    & R@5   & f1  \\ \hline
		مدل پایه جادوگر ویکی‌پدیا    & 23      & 1231 & 12.132 & 12.34 & 123 \\ \hline
		دو لایه با اندازه نهان ۱۲۸   & 123     &      & 123    &       & 13  \\ \hline
		چهار لایه با اندازه نهان ۲۵۶ &         &      &        & 132   & 123 \\ \hline
		چهار لایه با اندازه نهان ۵۱۲ &         & 132  &        &       & 132 \\ \hline
		شش لایه با اندازه نهان ۲۵۶   &         &      &        &       & 132 \\ \hline
	\end{tabular}
\end{table}


\section{ارزیابی مدل تولید پاسخ}

\subsection{مقدمه}
در این بخش مدل‌های پیشنهاد شده در بخش‌های 
\ref{chap4:generation:bert2bert}
و
\ref{chap4:generation:bart}
پیاده‌سازی و نتایج عملکرد آن‌ها گزارش شده است. از آنجایی که هنگام تولید پاسخ، استراتژی‌ها و رویکرد‌های متفاوتی را می‌توان در پیش گرفت (نظیر اتخاذ اندازه پرتو یا حریصانه یا بهینه اعمال کردن در هنگام تولید متن) ؛ تاثیر اتخاذ این سیاست‌های مختلف نیز در مورد هر مدل بررسی شده است.

عملکرد هر یک از مدل‌ها در تولید پاسخ، با استفاده از معیار‌های امتیاز مشابهت
\lr{F1}
با پاسخ صحیح، میزان سرگشتگی مدل در هنگام تولید پاسخ صحیح و معیار
\lr{BertScore}
پاسخ تولید شده، سنجیده شده است.

دادگان آموزشی اصلی مورد استفاده در این بخش دادگان  مربوط به پاسخ‌های تولیدشده توسط نقش معلم در جادوگر ویکی پدیا هستند. این دادگان در مجموع ۴۱۴۸۹ نمونه هستند. هر یک از این نمونه‌ها دارای سه جز اساسی تاریخچه گفتگو، جمله دانش و پاسخ است که دنباله متشکل از تاریخچه گفتگو و جمله دانش برای هر یک از نمونه‌ها به وسیله استراتژی مشابه با مورد بخش
\ref{chap4:solution:recom}
به دنباله‌هایی با حداکثر طول ۱۲۸ توکن محدود می‌شوند. این نمونه‌های سپس به ۲۵۹۴ دسته شانزده تایی تقسیم می‌شوند. با این حال در زمان آموزش با استفاده از شگرد 
\trans{تجمیع گرادیان}{gradient accumulation}
، هر چهار گام یکبار عمل به روزرسانی و بهینه‌سازی روی شبکه صورت خواهد گرفت (به عبارت بهتر پس از مشاهده هر چهار دسته ۱۶ تایی شبکه مورد آموزش توسط بهینه‌ساز واقع خواهد شد). بهینه‌ساز مورد استفاده در این بخش نیز مانند مسئله قبلی بهینه‌ساز آدام است که نرخ یادگیری آن نرخ ثابت 
$1e-5$
است. 
\subsubsection{مدل برت به برت}


\subsubsection{مدل بارت}


\section{ارزیابی کلی گپ‌زن}