\chapter{راهکار پیشنهادی}\label{chap4}
\minitoc

پس از تعریف مساله و مرور پژوهش‌های پیشین مرتبط با آن و ارائه مبانی نظری، در این راهکاری پیشنهادی برای مساله گپ‌زن دانش بنیان طرح خواهد شد. این طرح شامل ارائه کلیات درباره دو بخش انتخاب دانش و تولید پاسخ است و در جزییات هر یک از این بخش‌ها نیز تشریخ می‌شود. 


\section{ساختار کلی مدل پیشنهادی}
در این پژوهش خلق یک گپ‌زن دانش بنیان 
با عنایت به طرح کلی مدل جادوگر ویکی پدیا،
معادل با حل سه زیر مساله در نظر گرفته شده است و ارائه مدل برای این سه زیرمساله حل گشتن مساله اصلی را نتیجه می‌دهد.در واقع گپ‌زن در هر نوبت از یک مکالمه که بایستی پاسخ خود را تولید کند می‌بایست این سه مرحله را طی کند. این سه زیرمساله عبارتند از:

\begin{enumerate}
	\item 
	\textbf{استخراج اسناد مرتبط}
	در ابتدا گپ‌زن باید بتواند با توجه به تاریخچه مکالمه و پاسخ‌های نوبت‌های قبلی خود و طرف مقابلش، اسناد مرتبط را از منبع دانش خود که می‌تواند شامل چند صد هزار سند متنی باشد استخراج کند. این کار به منظور تمرکز بر روی چند سند مرتبط با مکالمه به جای پردازش کل منبع دانش (که طبیعتا غیرممکن است) صورت می‌گیرد. ورودی این بخش تاریخچه گفت‌ و گو و منبع دانش است و خروجی آن نیز اسناد انتخاب شده از منبع دانش است. 
	\item 
	\textbf{انتخاب دانش}
	پس از انجام مرحله قبل،‌اکنون گپ‌زن با تعدادی سند متنی روبرو است که خود شامل پاراگراف‌ها و جملاتی هستند. قاعدتا تمامی این جملات و پاراگراف‌ها در تولید پاسخ نوبت‌ بعدی موثر و مفید نیستند. از این رو گپ‌زن باز بایستی محدوده جستجوی خود را
	با توجه به تاریخچه گفت و گو محدودتر و متمرکزتر کند. 
	ورودی این مرحله، اسناد انتخاب شده در مرحله اول و خروجی آن نیز می‌تواند یک یا چند جمله 
	به عنوان جمله دانش باشد. ضمن این که گپ‌زن می‌بایستی توان این را داشته باشد که در صورتی که مکالمه‌اش نیازی به جمله دانش نداشت، در خروجی این مرحله این مطلب را اعلام کند. 
\footnote{برای مثال در صورتی که مخاطب از گپ‌زن پرسید که "سلام خوبی؟"، گپ‌زن برای پاسخ به این مکالمه نیازی به استفاده از منبع دانش خود ندارد.}
	\item
	\textbf{تولید پاسخ}
	در این گام، گپ‌زن حال بایستی با جمله یا جملات دانشی که در مرحله قبل انتخاب کرده است و با توجه به تاریخچه گفتگو، پاسخ مطلوب را تولید کند. ورودی این بخش جمله دانش و تاریخچه گفتگو هستند و خروجی آن نیز پاسخ گپ‌زن است. 
	
	
\end{enumerate}

	\trans{مدل پایه}{baseline model}
انتخابی برای مقایسه با محصول این پژوهش، مدل جادوگر ویکی‌پدیا (ارائه شده در بخش 
\ref{chap2:intro:wizard}
)
است. دادگان پایه مورد استفاده در این پژوهش نیز همان دادگان مدل جادوگر ویکی‌پدیا است. 

از آنجایی که در روند جمع‌آوری دادگان جادوگر ویکی‌پدیا،‌ عوامل انسانی تنها مجاز به بناکردن جواب خود بر اسناد پیشنهاد‌شده توسط موتور جستجوگر استفاده شده بودند، در این پژوهش نیز
برای حل زیر مساله استخراج اسناد مرتبط
از مدل بازیابی اطلاعاتی 
\lr{DRQA}
استفاده شده در جمع‌آوری دادگان و مدل جادوگر ویکی‌پدیا استفاده شده است. به علاوه این تصمیم کمک می‌کند تا کیفیت مدل‌های انتخاب دانش و تولید پاسخ مدل حاصل از این پژوهش با مدل پایه بهتر مقایسه شوند. شایان ذکر است که این مدل بازیابی اطلاعاتی بر روی اسناد ویکی‌پدیا عمل جستجو را انجام می‌دهد و در نتیجه منبع دانش گپ‌زن ما ویکی پدیا است.

ساختار کلی پیشنهاد شده دارای دو مزیت است. مزیت اول این است که این مدل
به آسانی و با تعویض منبع دانش قابل سوارشدن بر روی سایر منابع دانش متنی است. مزیت دوم نیز است که، به علت جدا بودن زیر مسائل از هم، می‌توان در هر بخش راهکار منحصر به فردی را که مخصوص آن بخش است پیشنهاد داد و عملکرد هر بخش را جداگانه بهینه کرد. برای مثال می‌توان در بخش انتخاب دانش از مدل‌های از پیش آموزش داده‌ای که بازنمایی بهتری از متن ارائه میدهند استفاده کرد و در بخش تولید پاسخ نیز از مدل های از پیش آموزش داده شده‌ای که در وظیفه تولید متن قوی‌ترند بهره برد.

این طراحی غیر انتها به انتها و قطعه قطعه اما خود از عیب جانبی رنج می‌برد و آن نیز احتمال انتقال خطا از گامی به گام دیگر است. برای مثال در صورتی که مدل انتخاب دانش به اشتباه جمله‌ای را برگزیند، در گام بعدی نیز مدل تولید پاسخ با ورودی غلطی مواجه شده و خروجی غلطی را تولید می‌کند. از این رو پیمانه‌ای بودن این مدل و غیر انتها به انتها آموزش دیدن آن را می‌توان یکی از چالش‌های اساسی آن برشمرد.
\section{روش پیشنهادی برای بخش انتخاب دانش}

\subsection{پیشنهادات}

در روش پیشنهادی مدل پایه برای زیرمساله انتخاب دانش، تاریخچه گفت و گو و جملات نامزد دانش همگی با یک ترنسفورمر یکسان و به طور مستقل از یکدگیر رمز می‌شوند. سپس مشابهت هر یک از جملات نامزد دانش با تاریخچه، از طریق محاسبه ضرب داخلی بردار رمز جمله نامزد با بردار رمز تاریخچه حساب می‌‌شود و در نهایت
جمله نامزد با بیشترین میزان مشابهت با تاریخچه، به عنوان جمله دانش انتخاب می‌گردد. در هنگام آموزش مدل نیز،‌ این شبکه از طریق کاهش انتروپی متقاطع میزان شباهت جملات نامزد دانش با تاریخچه، آموزش می‌یابد. با توجه به تابع هزینه استفاده شده در این مدل، می‌توان آن را به نوعی مشابه مسئله دسته‌بندی چند دسته‌ای در نظر گرفت. 

دو اشکال بزرگ را بر مدل مذکور می‌توان وارد دانست. اولین اشکال در نحوه رمز شدن مستقل هر یک از جملات نامزد نسبت به تاریخچه گفت و گو است. در واقع این طرح که هر یک از جملات نامزد و تاریخچه به صورت مستقل رمز شوند و در نهایت برداز بازنمایی حاصل از آن‌ها با یکدیگر مشابهت سنجی شود طرح معیوبی است؛ چه آن که در هنگام رمزشدن ممکن است ويژگی‌های متمایز جملات نامزد حذف شده یا بار اطلاعاتی آن‌ها در بردار رمز کاهش یافته باشد و از آن‌جایی که اکثریت آن‌ها با همدیگر از یک سند اطلاعاتی استخراج شده‌اند، در نتیجه ممکن است که بردار رمز همگی‌ آن‌ها در یک محدوده کوچک واقع شود. در این حال برای یافتن میزان مشابهت میان بردار رمز تاریخچه و هر یک از جملات نامزد نمی‌توانیم تنها به معیار ساده ضرب داخلی تکیه کنیم. به علاوه، در بسیاری از حالت توجه توام و همزمان مدل به تاریخچه و جمله دانش در راه پیدا کردن میزان مشابهت آن‌ها می‌تواند موثرتر از توجه مستقل شبکه به هر یک از آن‌ها باشد. 

پیشنهاد اساسی ما این است که به جای آموزش دادن مدلی جهت یادگیری ارائه بازنمایی از جملات و سپس محاسبه میزان شباهت بردار‌های بازنمایی آن‌ها، یک مدل را جهت محاسبه میزان شباهت دو دنباله متنی آموزش دهیم. در واقع این مدل پیشنهادی در ورودی خود دو دنباله را می‌گیرد (تاریخچه و جمله نامزد) و در خروجی خود میزان شباهت این دو دنباله متنی را برمی‌گرداند. نقطه قوت این مدل می‌تواند در توجه توام و همزمان دنباله تاریخچه و جمله نامزد نسبت به یکدیگر باشد. در صورت استفاده از این مدل، برای یافتن جمه دانش، کافی است تا میزان مشابهت هر یک از جملات نامزد نسبت به دنباله تاریخچه محاسبه شده و سپس جمله‌ نامزد با بیشترین مشابهت به عنوان جمله دانش انتخاب شود. 

دومین اشکال وارد بر مدل انتخاب دانش جادوگر ویکی‌پیدا را می‌توان در طرز آموزش آن دانست. استفاده از تابع انتروپی متفاطع بین میزان شباهت جمله‌های نامزد با تاریخچه در هنگام آموزش، مدل را متمایل می‌کند تا صرفا به بالابردن امتیاز جمله درست توجه کند. تابع انتروپی متقاطع در مسائل دسته‌بندی که هر نمونه تنها می‌تواند متعلق به یک کلاس باشد موثر واقع می‌شود؛ اما در زیرمساله انتخاب دانش که ذات مساله بیشتر بر مسائل
\trans{رتبه‌بندی}{Ranking}
تکیه دارد، می‌تواند باعث کج فهمی مدل شود. مدل بایستی به جای آموزش بر این گمانه که میزان شباهت تاریخچه با جمله درست دانش نسبت به میزان شباهت تاریخچه با هر یک جملات غیردرست بایستی مانند نسبت به صفر به یک باشد؛ بر این اصل آموزش ببیند که میزان شباهت تاریخچه با جمله درست از میزان شباهت تاریخچه با جمله غیردرست بیشتر است. 

بنابراین پیشنهاد دوم ما بر این است که به جای آن که مدل در هنگام آموزش هر بار امتیاز مشابهت جمله درست دانش و همه جملات نادرست دانش را همزمان در نظر بگیرد، هر بار به مقایسه میزان مشابهت یک جفت جمله دانش درست و جمله دانش نادرست بپردازد. به فرض مثال اگر برای یک تاریخچه چهل جمله از منبع دانش استخراج شده باشد که یکی از آن‌ها درست باشد و باقی جملات نادرست باشند، در روش جادوگر ویکی پدیا امتیاز مشابهت این چهل جمله همزمان با یکدگیر مقایسه می‌شود، در حالی که در روش پیشنهاد شده، جمله دانش درست بایستی در سی و نه رقابت با سی و نه جمله نادرست یک به یک پیروز شود. ترکیب این پیشنهاد 
و پیشنهاد قبل، می‌تواند باعث خلق مدلی شود که در زمینه مساله رتبه‌بندی 
و یا برای مثال پیشنهاد پنج جمله دانش به جای یک جمله دانش
برتر از مدل جادوگر ویکی‌پدیا عمل کند.

پیشنهاد سوم ما استفاده از مدل‌های برت مینیاتوری در طراحی معماری مدل زیرمساله انتخاب دانش است
\cite{turc2019well}.
این مدل‌ها از طرفی حجم‌شان آن قدر بزرگ نیست که نتوان آن‌ها را بر روی سخت‌افزار‌های هرچند محدود در دسترس آموزش داد و برای وظیفه موردنظر تنظیم کرد و از طرف دیگر، قدرت آ‌ن‌ها و عصاره دانش قرار گرفته در پارامتر‌های این شبکه می‌تواند نقطه آغاز خوبی برای آموزش شبکه هدف باشد. به علاوه در صورتی که ما یک معماری را از نو و بدون پیش آموزش بر روی دادگان خود آموزش دهیم، این بیم می‌رود که مدل حاصل در نهایت بر روی موضوعات دیده شده در دادگان بیش برازش کرده و نتواند قدرت تعمیم دهی به سایر موضوعات را داشته باشد. 

\subsection{معماری پیشنهادی}

مدل پیشنهادی ارائه شده در این پژوهش در واقع  متکی بر یک شبکه عصاره‌‌گرفته شده از برت است (که خود می‌تواند در تنظیمات مختلف تعداد لایه و اندازه حالت نهان باشد). 
ورودی‌های این شبکه تاریخچه گفت و گو و جمله دانشی هستند که قرار است میزان شباهت آن‌ها توسط شبکه خروجی داده شود. تاریخچه گفتگو، خود از متن نوبت‌های مختلف گفتگو میان گپ‌زن و عامل انسانی پیشرو او تشکیل شده اند. این نوبت‌ها به ترتیت به یکدیگر از سمت راست الحاق شده و بین هر دو نوبت نیز توکن 
$[SEP]$
به منظور نشان دادن به پایان رسیدن نویت جای می‌گیرد. سپس جمله دانش مورد نظر نیز از سمت راست به تاریخچه گفت و گو الحاق می‌شود و مانند قبل، بین تاریخچه گفت و گو و جمله دانش نیز یک توکن 
$[SEP]$
قرار می‌گیرد. حال با یک دنباله متنی مواجه هستیم که مرز میان نوبت‌های مختلف گفتگو و جمله دانش در آن با 
$[SEP]$
از یکدیگر جدا شده است. سپس توکن‌های 
$[CLS]$
و 
$[SEP]$
به ترتیب به ابتدا و انتهای این دنباله متنی اضافه می‌شوند. 

دنباله متنی حاصل به شبکه عصاره‌گرفته‌شده برت 
با اندازه حالت نهان 
$d_{model}$
ورودی داده می‌شود. سپس بردار بازنمایی رمزشده متعلق به توکن
$[CLS] $
که به نوعی بازنمایی تمام دنباله است،‌ به وسیله 
یک لایه پیشرو تمام متصل با اندازه
$d_{model}$
به 
$1$،
 به عدد 
 $o$
  تبدیل می‌شود. حال این عدد $o$ نیز طبق رابطه زیر به میزان مشابهت که $similarity$ نام دارد تبدیل می‌شود. 
  
  \begin{gather}\label{eq:similarity_equation}
  similarity = \frac{\tanh{(o)}-(-1)}{2}
  \end{gather}

رابطه 
\ref{eq:similarity_equation}
کمک می‌کند تا میزان مشابهت خروجی از شبکه همواره عددی بین صفر و یک باشد. 

\subsection{توابع هزینه}
در بخش قبل ساختار پیشنهادی معماری شبکه‌ای که قادر به محاسبه میزان شباهت تاریخچه و جمله دانش باشد ارائه شد. حال بایستی نحوه آموزش و بهینه‌کردن شبکه مطرح شود. به صورت کلی همان‌طور که در قسمت پیشنهادات ابتدای فصل مطرح شد، بایستی هر بار میزان مشابهت تاریخچه با جمله درست دانش و میزان مشابهت تاریخچه با جمله نادرست دانش با یکدیگر سنجیده شده و مقدار عبارت اول بیشتر از دومی باشد. ما در ادامه عبارت اول را 
$true\:similarity$
و عبارت دوم را نیز
$false\:similarity$
نامگذاری می‌کنیم. در ادامه دو تابع هزینه جهت نیل به هدف مطرح شده ارائه شده اند:

\begin{itemize}
	\item 
	\textbf{
	تابع خطای انتروپی متقاطع 
	\trans{دوتایی}{binary}
	:
	}

	رابطه این تابع که از ایده مدل رگرسیون منطقی برآمده است در رابطه
	\ref{eq:log_loss_function}
	آمده است. 
\begin{gather}\label{eq:log_loss_function}
\mathcal{L}_{log} = -\log{(true\:similarity)} -  \log{(1-false\:similarity)} 
\end{gather}


	\item
	\textbf{
	تابع خطای خطی:
	}

\begin{gather}\label{eq:linear_loss_function}
\mathcal{L}_{lin} = -true\:similarity + false\:similarity 
\end{gather}


\end{itemize}


\section{روش پیشنهادی برای بخش تولید پاسخ}

\subsection{معماری پیشنهادی}

\subsubsection{معماری برت به برت}

\subsubsection{معماری مبتنی بر بارت}



\section{مقدمه}
تا به حال به لحاظ نظری به نحوه حل مسئله پرداخته شد. در این فصل پس از معرفی دادگان آموزشی و معیارهای ارزیابی مورد استفاده، نحوه پیاده‌سازی و دشواری‌های پیش‌آمده هنگام آموزش شرح داده خواهند شد. در انتها نیز ضمن گزارش نتایج، عملکرد مدل‌ها با یکدیگر مقایسه شده‌اند.
\section{دادگان آموزشی} \label{chap4:dataset}
\bff{\lr{Stanford Sentiment Treebank (SST)}}:
این دادگان حاوی حدود ۱۱ هزار نظر مثبت و منفی راجع به فیلم‌ها است \cite{sst}. به مانند سایر مدل‌ها جملات با طول کمتر از ۲۵ کلمه انتخاب شد که باقی مانده، ۲۲۰۷ جمله مثبت و منفی دادگان آموزشی، ۹۴۶ جمله دادگان \validation{} و ۱۳۵۰ جمله دادگان آزمون با اندازه واژگان ۷۴۷۹ خواهد بود.
\\
\bff{\lr{Yelp Restaurant (Yelp)}}:
این دادگان حاوی حدود ۶۰ هزار نظر مثبت و منفی کاربران راجع به رستوران‌ها است که زیرمجموعه‌ای از دادگان اصلی است
\LTRfootnote{\url{https://www.yelp.com}}.
حداکثر طول این جملات ۳۰ و با اندازه واژگان ۷۸۰۲، ۴۵ هزار داده آموزشی، ۵ هزار جمله \validation{} و ۱۰ هزار جمله دادگان آزمون است
\footnote{
	این دادگان از آدرس زیر تهیه و نمونه‌برداری شده است.
	\\
	\url{https://github.com/shentianxiao/language-style-transfer}}.
\\
\bff{\lr{Amazon Application-Book Review (Amazon)}}:
این دادگان حاوی حدود ۲۲۰ هزار نظر کاربران راجع به کتاب و یا برنامه‌های موجود در فروشگاه \lr{Amazon} است که زیرمجموعه‌ای از دادگان اصلی است \cite{amazon_review}. در واقع این دادگان بر خلاف دو دادگان دیگر، دارای شروط مثبت و منفی نبوده و شروط آن موضوع نظر که شامل کتاب یا برنامه است، می‌باشد. حداکثر طول این جملات ۴۰ و اندازه واژگان ۶۲۸۲ بوده و شامل 174622 داده آموزشی، 19402 جمله \validation{} و 19436 داده آزمون است
\footnote{
	دادگان \amazon{} و دادگان \sst{} از آدرس زیر تهیه شده اند.
	\\
	\url{https://github.com/williamSYSU/TextGAN-PyTorch}}.
\\
لازم به ذکر است در تمامی دادگان فوق، تعداد داده‌های شروط مختلف یکسان است.
\section{معیارهای ارزیابی} \label{chap4:metrics}
در ابتدا لازم است تا متذکر شد، از آنجا که در مدل‌های با فضای نهان امکان محاسبه دقیق \likelihood{} وجود ندارد، این معیار از معیارهای ارزیابی حذف گردیده است. به عنوان جایگزین از معیار‌های مبتنی \ngramphrase{} استفاده خواهد شد.
\subsection{\bleu{}}
معروف‌ترین معیار مبتنی بر \ngramphrase{} معیار \bleu{} است. این معیار در اصل در حوزه ترجمه ماشین معرفی شده است و کاربرد فراگیری دارد. این معیار که
\trans{همبستگی}{Correlation}
آن با قضاوت انسانی تایید شده است \cite{bleu}، بر اساس مشابهت \ngramphrase{} جملات ترجمه شده تولیدی با جملات ترجمه موجود در دادگان آزمون است. از آنجا که برای یک جمله چندین ترجمه وجود دارد، به میزانی که \ngramphrase{}‌های جمله تولیدی با تعداد بیشتری از مجموعه \ngram{}‌های جملات ترجمه شده مرجع (آزمون)‌همخوانی داشته باشد، مدل امتیاز بالا‌تری خواهد گرفت. لازم به ذکر است که خروجی این معیار عددی بین صفر و یک بوده و اعداد بالاتر نشان دهنده کیفیت بالاتر جمله ترجمه شده است \cite{bleu}.
\\
این روش ارزیابی در حوزه تولید متن نیز بسیار کاربرد دارد. از آنجا که در تولید متن، مفهوم جمله مبدأ و مقصد وجود ندارد تا شباهت با جمله مقصد مقایسه شود، همه دادگان آزمون به عنوان مجموعه مرجع فرض خواهد شد و شباهت تک تک جملات تولید شده با مجموعه آزمون اندازه‌گیری و گزارش می‌شود \cite{seqgan}. در نهایت میزان شباهت هر جمله تولید به مجموعه مرجع به دست می‌آید که میانگین آن‌ها، امتیاز \bleu{} برای کل مجموعه تولید شده را خواهد ساخت.
\\
نکته منفی این معیار، حساس نبودن آن به تنوع جملات است. از آنجا که شباهت هر جمله تولیدی مستقل از سایر جملات ارزیابی می‌شود، حتی اگر مدل تعداد زیادی جمله یکسان اما با کیفیت تولید نماید، عدد بالایی به مدل اختصاص خواهد یافت و این موضوع مطلوب نیست \cite{jointly}.
\\
لازم به ذکر است که در این معیار و تمامی دیگر معیارهای مبتنی بر \ngramphrase{}، حداکثر طول \ngramphrase{} مشخص است. برای مثال اگر حدااکثر طول \ngramphrase{} در نظر گرفته شده ۲ باشد، به به آن \bleu[-2]{} گفته می‌شود.
\subsection{\selfbleu{}}
این معیار نیز بسیار به لحاظ محاسباتی شبیه معیار \bleu{} است اما حساس به تنوع جملات تولیدی و غیر حساس به کیفیت جملات است. در این معیار، شباهت هر جمله با سایر جملات تولیدی اندازه‌گیری می‌شود؛ واضح است که هر اندازه شباهت جملات به یکدیگر کمتر باشد، از نظر این معیار امتیاز بهتری کسب خواهد کرد. به طور دقیق‌تر شباهت \bleu{} هر جمله با در نظر گرفتن سایر جملات به عنوان مجموعه مرجع، معیار \selfbleu{} خواهد بود \cite{seqgan}. همان طور که از شرح معیار بر‌می‌آید، این معیار کیفیت جملات را در نظر نگرفته و تنها شباهت جملات تولیدی به یکدیگر و یا به عبارت دیگر تنوع جملات را اندازه‌گیری می‌کند \cite{jointly}. لازم به ذکر است که مدل با نمونه‌ها متنوع عددی نزدیک به صفر و مدل با نمونه‌های تنوع کم عددی نزدیک به یک کسب خواهد کرد.
\subsection{\jaccard{}}
از آنجا که دو معیار \bleu{} و \selfbleu{} هر کدام به تنهایی به ترتیب ارزیابی‌گر کیفیت و تنوع هستند، معیار دیگری به نام \jaccard{} وجود دارد که ترکیب کیفیت و تنوع را در نظر می‌گیرد \cite{jointly}. این معیار بر خلاف \bleu{} که هر جمله را مستقل از سایر جملات تولیدی با مجموعه مرجع مقایسه می‌کرد، شاخصه‌های کل مجموعه تولیدی را با شاخصه‌هایی از کل مجموعه مرجع (آزمون)‌مقایسه می‌کند که این شاخصه تعداد تکرار هر \ngramphrase{} است.

اگر بخواهیم به صورت دقیق تعریف کنیم، فرض کنید دو مجموعه جمله $S_1$ و $S_2$ در اختیار داریم که مجموعه \ngramphrase{}‌های همه جملات را با $G_n$ و تعداد تکرار هر \ngramphrase{} در مجموعه $S$ را با $C_n(g,S)$ که $g$،
\ngramphrase{}
مذکور است، نشان می‌دهیم. میزان شباهت مجموعه \ngramphrase{}‌های مجموعه $S_1$ و $S_2$ به صورت تعریف می‌شود \cite{jointly}:

\begin{gather}
	\text{score}_n = \frac
	{
		\sum_{g \in G_n} \min \{ C_n(g, S_1), C_n(g, S_2) \}
	}
	{
		\sum_{g \in G_n} \max \{ C_n(g, S_1), C_n(g, S_2) \}
	}
\end{gather}
میانگین هندسی 
$\{\text{score}_n\}_{n=1}^N$
معیار \jaccard[-N]{} خواهد بود که $N$ بیشینه طول \ngramphrase{}‌ها است.
با توجه به تعریف فوق اگر شاخصه‌ای از مجموعه تولیدی با مجموعه مرجع، چه به دلیل عدم رعایت کیفیت و چه عدم رعایت تنوع همخوانی نداشته باشد، از طریق کوچک شدن صورت کسر و بزرگ شدن مخرج کسر، جریمه خواهد شد \cite{jointly}.
\subsection{درصد رعایت شرط}
معیارهای معرفی شده تا به حال، کیفیت و تنوع جملات را مستقل از شرط بررسی می‌کردند. برای بررسی مدل‌ها از این جهت نیز می‌توان از یک \classifier{} قدرتمند بهره برد
\cite{toward, sentigan}؛
به این صورت که برای مثال اگر شرط با دو مقدار مثبت و منفی داشته باشیم، تعدادی برچسب مثبت و منفی اولیه در نظر گرفته؛ توسط مدل، جملات با مقدار شروط متناظر تولید نموده و در نهایت برچسب این جملات توسط \classifier{} تعیین نمود. درصد تطابق برچسب‌های \classifier{} با برچسب‌های اولیه دقت در رعایت شرط خواهد بود
\cite{toward, sentigan}.
در مقالات گذشته به دلیل معرفی نشدن مدل‌های \pretrain{} شده عظیم همچون \lr{BERT} از \classifier{}های دیگری استفاده می‌شد. این شبکه‌ها با
\trans{به‌آموزی}{Fine-tuning}
بر روی \task{}‌های مختلف، در بسیاری از \task{}ها موفق به کسب \stateoftheart{} شده‌اند \cite{bert}. اما نکته این دسته از مدل‌ها حجم زیاد آن‌هاست. بارگذاری  این مدل‌ها در \gpu{} و \finetuning{} آن‌ها به حافظه زیادی نیاز است. به همین هدف مدل‌های دیگری با اندازه کوچکتر با امکان بارگذاری در \gpu{}‌ در دسترس عموم، امکان \finetuning{} را فراهم کرده‌اند. نسخه کم حجم شده \lr{BERT}،
\lr{DistilBERT}
نام دارد که در دادگان \lr{SST} دقت ۹۴ درصد برای آن گزارش شده است \cite{distilbert}. با استفاده از این شبکه و \finetuning{} آن بر روی هر دادگان به طور مجزا به درصد دقت‌های ۸۷، ۹۷ و ۹۹ در به ترتیب دادگان \sst{}، \yelp{} و \amazon{} رسیده شد.
\iffalse
	می‌توان به عنوان جایگزین از معیارهایی همچون \revperplexity{} استفاده نمود. این روش به این صورت است که یک مدل زبانی میانی با استفاده از نمونه‌های مدل آموزش داده شده و \likelihood{} نمونه‌های آموزشی در مدل آموزش داده شده اندازه‌گیری می‌شود. این معیار نیز حساس به کیفیت و تنوع است. اگر مدل میانی آموزش داده شده، چه به دلیل عدم تنوع  و یا عدم کیفیت نمونه‌های مدل مورد ارزیابی احتمال کمی به نمونه‌های آموزشی نسبت دهد، معیار حساس بوده و مدل را جریمه خواهد کرد. نکته قابل توجه این است که به دلیل اینکه معیار آموزش مدل میانی، بر اساس بیشینه کردن \likelihood{} است، این امکان وجود دارد تا مدل مورد آموزش رفتار \meanseeking{} از خود بروز داده و به نقاطی که نمونه آموزشی از آن‌ها وجود ندارد، احتمال بالایی نسبت دهد. اما این اتفاق زمانی رخ می‌دهد که ظرفیت مدل کمتر از پیچیدگی نمونه‌های آموزشی باشد؛ این در حالیست که این نمونه‌های آموزشی توسط مدل مشابهی با ظرفیت مشابه تولید شده اند و احتمالا چنین نگرانی‌ای وجود نخواهد داشت.
\fi
\section{آموزش مدل}
همان طور که در فصل \ref{chap3} توضیح داده شد، مدل پیشنهادی اول از دو بخش کلی تشکیل شده است. اولین بخش مربوط به آموزش \wae{} است. به این منظور از معماری \transformer{} در \encoder{} و \decoder{} با بردارهای  \embedding{}
۱۲۸ تایی و فضای نهان ۵۱۲ بُعدی استفاده شد که \encoder{} چهار لایه و \decoder{} دو لایه دارد. لازم به ذکر است که ۴ خروجی اولِ لایه آخر \encoder{} به عنوان بردار فضای نهان به کار بسته شده است. نتایج با سایر معماری‌ها نیز گزاش شده‌ است. برای مولد شرطی نیز از دو لایه \lr{MAF} که هر لایه آن شامل سه لایه \lr{MADE} است بهره برده شده است. طبیعتا اندازه ورودی و خروجی این شبکه نیز ۵۱۲ بُعدی خواهد بود. در مورد مدل پیشنهادی دوم نیز تمام بخش‌ها بدون تغییر هستند؛ تنها از بردار \embedding{}
۱۲۸ تایی برای هر مقدار شرط در نظر گرفته شده است. لازم به ذکر است تعداد پارامتر‌های \decoder{} در مدل‌های پیشنهادی و مدل مولد \sentigan{} (منظور یک مدل مولد تنها است و نه تمام مدل‌های مولد موجود به ازای تمام مقادیر شروط) یکسان است اما در مدل \towardctg{} به دلیل اینکه، بردار شرط و بردار فضای نهان، هر دو به عنوان بردار نهان اولیه \lr{RNN} و همچنین در کنار بردار \embedding{} کلمات وارد شبکه می‌شوند، تعداد پارامتر‌های شبکه \towardctg{} تقریبا ۳ برابر مدل‌های پیشنهادی است.
\\
همان طور که در بخش \ref{chap3:wae_training} توضیح داده شد، \decoder{} بایستی
$G(Z) = \argmax_{x} P_\psi(x|Z)$
و فضای خروجی $P_\psi$ یک بردار $|V|^{m}$ بعدی است که $m$ حداکثر طول جملات و $|V|$ نیز اندازه واژگان است؛ اما از آنجا که توانایی محاسباتی یافتن $\argmax$ بر روی چنین فضای بزرگی را نداریم بنابراین از روش
\trans{کدگشایی حریصانه}{Greedy decoding}
که تقریبی از $\argmax$ بر روی کل فضاست استفاده می‌کنیم. همچنین لازم به ذکر است که آموزش مدل پیشنهادی و مدل‌های پایه، در سطح کلمه است و نه حرف و یا زیرکلمه. علت این انتخاب نیز بزرگ نبودن اندازه واژگان دادگان مورد استفاده بوده و مشکلی از این جهت وجود نداشت. علاوه بر این، آموزش به صورت 
\trans{پشته}{Batch}ای
است؛ برای مثال در خطای بازسازی ۱۲۸ جمله به مدل، ورودی داده شده و خطای بازسازی همان ۱۲۸ جمله اندازه‌گیری خواهد شد.

\subsection{معماری‌های متفاوت در \encoder{} و \decoder{}}
به منظور بررسی اثر معماری‌های مختلف بر آموزش یک \wae{}، حالت‌های مختلف مورد آزمایش قرار گرفت. از دو معماری قدرتمند \lstm{} و \transformer{} در \decoder{} و سه معماری \lstm{}، \cnn{}  و \transformer{} در \encoder{} استفاده شده و نتایج در شکل \ref{fig:chap4:archs} آمده است. لازم به ذکر است که تعداد پارامتر‌های معماری‌های مختلف تقریبا نزدیک به یکدیگر بوده و اندازه \embedding{} کلمات با یکدیگر یکسان در نظر گرفته شده است.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.3\textheight}
		\centering
		\includegraphics[width=1.\textwidth]{images/figs/bleu2-random.png}
		\caption{کارایی مدل‌های مختلف بر اساس معیار \bleu[-2]{}}
		\label{fig:chap4:archs_bleu}
	\end{subfigure}
	\begin{subfigure}{0.3\textheight}
		\centering
		\includegraphics[width=1.\textwidth]{images/figs/selfbleu2-random.png}
		\caption{کارایی مدل‌های مختلف بر اساس معیار \selfbleu[-2]{}}
		\label{fig:chap4:archs_selfbleu}
	\end{subfigure}
	\begin{subfigure}{0.3\textheight}
		\centering
		\includegraphics[width=1.\textwidth]{images/figs/jaccard2-random.png}
		\caption{کارایی مدل‌های مختلف بر اساس معیار \jaccard[-2]{}}
		\label{fig:chap4:archs_jac}
	\end{subfigure}
	\begin{subfigure}{0.3\textheight}
		\centering
		\includegraphics[width=1.\textwidth]{images/figs/nll.png}
		\caption{
			کارایی مدل‌های مختلف بر اساس معیار خطای بازسازی (منفی لگاریتم \likelihood{} باز‌سازی جمله)}
		\label{fig:chap4:archs_nll}
	\end{subfigure}
	\caption
	[
		کارایی معماری‌های مختلف در معیارهای
		\lr{BLEU-2}،
		\lr{Self-BLEU-2}،
		\lr{MS-Jaccard-2}
		و خطای بازسازی.
	]
	{
		کارایی معماری‌های مختلف در معیارهای \bleu[-2]{}، \selfbleu[-2]{}، \jaccard[-2]{} و خطای بازسازی.
		نام \lr{x-y} به معنای آن است که در \encoder{} از معماری x و در \decoder{} معماری y استفاده شده است. محور افقی تعداد \lr{epoch} است.}
	\label{fig:chap4:archs}
\end{figure}

همان طور که در شکل \ref{fig:chap4:archs_bleu} مشخص است، بهترین مدل بر اساس معیار \bleu[-2]{}، مدل \lr{CNN-RNN} است؛ اما میزان تاثیر فضای نهان بر خروجی \decoder{} چقدر است؟ به این منظور از معیار \selfbleu[-2]{} استفاده شده است. همان طور که در \ref{fig:chap4:archs_selfbleu} قابل رؤیت است، \selfbleu[-2]{} معماری \lr{CNN-RNN} عددی نزدیک به یک دارد؛ به این معنی که جملات تولید شده توسط این مدل، شباهت زیادی به یکدیگر دارند. بنابراین چنین مدلی مطلوب ما نخواهد بود. برای مقایسه همزمان این دو معیار از دو معیار دیگر \jaccard[-2]{} و خطای بازسازی استفاده نمودیم. همان طور که در شکل \ref{fig:chap4:archs_jac} مشخص است، بهترین مدل بر اساس این معیار، معماری \lr{Trans-Trnas} به معنای استفاده از معماری \transformer{} در \encoder{} و \decoder{}، است. از سوی دیگر کمینه مقدار خطای بازسازی طبق شکل \ref{fig:chap4:archs_nll} و همچنین متنوع‌ترین نمونه‌ها با توجه به معیار \selfbleu[-2]{} نیز اختصاص به همین مدل یافته است. بنابراین، معماری \transformer{} در این \task{} از سایر معماری‌ها موفق‌تر عمل کرده برای آزمایشات بعدی مورد استفاده قرار خواهد گرفت. در مورد سایر معماری‌ها نیز این طور باید گفت که مدل‌های دارای \transformer{} در \decoder{} دارای تنوع و \jaccard[-2]{} بالاتری هستند.
\iffalse
	\subsection{\encoder{}،
		عامل آموزش ناموفق}
	پس از آموزش شبکه توضیح داده شده، معضل عدم توجه \decoder{} به فضای نهان پیش آمد. تصاویر ؟؟؟ مربوط به نتایج \bleu{} و \selfbleu{} در دو حالت گزارش شده است. در حالت اول یک مجموعه جمله از دادگان
	\trans{اعتبارسنجی}{Validation}
	به فضای نهان برده شده و مجددا بازسازی ‌شده و \bleu{} و \selfbleu{} این مجموعه نسبت به داده آزمون اندازه‌گیری و گزارش شده است. این حالت را حالت بازسازی می‌نامیم. در حالت دوم تعدادی نمونه از \priordist{} گرفته شده و توسط \decoder{}
	\decode{}
	شده و مجددا معیارهای ذکر شده گزارش شده‌اند. این حالت را نیز حالت نمونه‌برداری می‌نامیم.
	مقادیر \bleu{} و \selfbleu{} دادگان \validation{} بر روی دادگان آزمون نیز به شرح زیر است:
	عکس بلو سلف بلو :)
	اعداد بلو سلف بلوی دیتا :)
	\\
	همان طور که در تصاویر ؟؟؟ مشخص است، با اینکه مقدار \bleu{} از دادگان اصلی بیشتر است (!) اما \selfbleu{} نزدیک به یک است! این موضوع نشان از این دارد که به ازای تغییرات $z$ در فضای نهان، خروجی \decoder{} تغییر چندانی نمی‌کند. مشاهده نمونه‌های تولید شده توسط مدل نیز گواهی بر این موضوع است.
	گواه موضوع :)
	\\
	حدس اولیه بر این بود که اتفاقی شبیه به آنچه در \vae{} گزارش شده است، رخ داده است. به منظور آزمایش دقیق‌تر یک \autoencoder{} ساده و بدون هیچ تابع هزینه اضافی آموزش داده شد. نتایج به شرح زیر بدست آمد:
	نتایج به شرح :)
	\\
	به وضوح مشخص است که پدیده مشابهی رخ داده است. بنابراین مشکل احتمالا از نحوه آموزش نیست. در گام بعدی تغییر معماری در \encoder{} و \decoder{} مورد بررسی قرار گرفت. معماری‌های مورد آزمایش \lr{LSTM}، \lr{CNN} و \lr{Transformer}  بودند. از آنجا که قدرت \lr{CNN} در تولید جمله در مقایسه با \lr{LSTM} کمتر است، از بررسی \lr{CNN} به عنوان \decoder{} صرف نظر شد. لازم به ذکر است که به دلیل اعمال نکردن توزیعی بر فضای نهان، اعداد برای حالت بازسازی گزارش شده‌اند.
	عکس معماری‌های متفاوت و ترکیبشان :)
	\\
	نکته قابل توجه این است که گویا مشکل در معماری \encoder{} نهفته است. در صورت استفاده از معماری \transformer{} مشکل عدم توجه به فضای نهان تقریبا رفع شده و \bleu{} و \selfbleu{} در حالت بازسازی تقریبا برابر با مقادیر این معیار برای دادگان \validation{} است. نکته قابل توجه دیگر این است که معماری \lstm{} و \transformer{} در \decoder{} تفاوت چندانی ایجاد نمی‌کند و تنها مسیر حرکت متفاوتی دارند.
	به دلیل همگرایی سریع‌تر معماری \transformer{}، این معماری برای سایر آزمایشات برگزیده شد. در ادامه با استفاده از معماری \transformer{} یک \wae{} آموزش داده شد که نتایج به شرح زیر است:
	شرح آزمایش :)
	\\
\fi
\iffalse
	\subsection{استفاده از  \gan{} به جای \mmd{}}
	در بخش‌های متفاوتی صحبت از رفتار \modecollapse{}
	\gan{}
	سخن به میان آمد. در اینجا طی یک آزمایش از \lr{WGAN} به جای \mmd{} برای یادگیری فضای نهان یک \autoencoder{} استفاده شد. به عبارت دیگر اگر $F(\epsilon)$ شبکه‌ای باشد که با گرفتن یک نوفه با توزیع گاوسی نرمال، آن را به نمونه‌ای در فضای نهان تبدیل کند و $D(Z)$ یک \critic{} بین نمونه‌های تولید شده توسط $F$ و فضای نهان ساخته شده توسط \encoder{}
	$Q(Z|X)$
	باشد، تابع هزینه ذیل استفاده گشت:
	\begin{gather}
		\mathcal{L}_\text{WGAN} (F, D)=
		\expected_{x \sim P_\text{Data}(X), z \sim Q(Z|x)} D(z)
		- \expected_{\epsilon \sim N(\bff{0}, \bff{I}), z \sim F(\epsilon)} D(z)
		\\
		\text{\lr{s.t: D is 1-Lipschitz}} \nonumber
	\end{gather}
	که نسبت به $D$ بیشینه و نسبت به $F$ کمینه می‌گردد. برای برآوردن شرط \lr{1-Lipschitz} بودن $D$ نیز از روش \lr{Gradient Penalty} استفاده شده است. اگر $\bff{z}$ و $\tilde{\bff{z}}$ به ترتیب نمونه‌هایی از $Q$ و $F$ ،
	$t$
	متغیر تصادفی از توزیع یکنواخت $[0,1]$ و
	$\hat{z} = t\bff{z} + (1 - t) \tilde{\bff{z}}$
	باشد، \lr{Gradient Penalty} به صورت زیر نوشته می‌شود \cite{wgan_gp}:
	\begin{gather}
		\mathcal{L}_\text{WGAN-GP} (D; \bff{z}, \tilde{\bff{z}}) = \lambda_{gp} \expected_{t \sim U(0, 1)}
		(|| \nabla_{\hat{\bff{z}}} D(\hat{\bff{z}}) ||_2  - 1)^2
	\end{gather}
	که در کنار تابع هزینه اصلی بهینه‌سازی می‌شود. نتایج آزمایش فوق به شرح زیر است:
	شرح آزمایش :)
	\\
\fi
\iffalse
	\section{آموزش مولد شرطی}
\fi

\iffalse
	\subsubsection{نمودار‌های آموزش \wae{} و مولد شرطی}
	نمودارهای مربوط به آموزش \wae{} و مولد شرطی با دادگان \amazon{} به ترتیب در شکل‌های \ref{fig:chap4:amazon_cond} و \ref{fig:chap4:amazon_flow} آمده است. کم شدن تابع هزینه در \ref{fig:chap4:amazon_enc_cls} را می‌توان به میزان دسته‌بندی شدن جملات در فضای نهان نسبت به مقادیر شرط و افزایش معیار \jaccard{} در شکل \ref{fig:chap4:amazon_flow_jaccard} را به یادگیری مطلوب فضای نهان توسط شبکه مولد، تعبیر نمود.
\fi

\section{نتایج و مقایسه با سایر مدل‌ها}
از بین مدل‌های شرطی ذکر شده، مدل‌های ساده به دلیل سادگی حذف و مدل \lr{CSGAN} نیز به دلیل ارائه نکردن کد پیاده‌سازی حذف شدند. بنابراین مدل‌های پایه شامل دو مدل \towardctg{} و \sentigan{} هستند اولی بر پایه \vae{} و دیگری بر پایه \gan{} است. در تمامی آموزش‌ها و برای تمامی مدل‌ها، اندازه بردار \embedding{} کلمات و فضای نهان مدل‌ها ۱۲۸ و بردار فضای نهان خروجی \encoder{}، ۵۱۲ در نظر گرفته شده است. در مورد معماری \encoder{} و \decoder{} نیز از معماری \transformer{} استفاده شده است.
\\
همان طور که در بخش \ref{chap4:dataset} توضیح داده شد، مدل‌ها بر روی دادگان آموزشی \lr{SST} آموزش داده شده و سپس بر اساس معیارهای  دقت رعایت شرط، \bleu{} ، \selfbleu{} و \jaccard{} مورد ارزیابی قرار گرفته‌اند. نتایج در جدول \ref{table:mr15_result} گزارش شده است.
به منظور نام گذاری، مدلی که مقدار شرط به طور کامل فضای نهان را تعیین می‌کند را مدل پیشنهادی ۱ و مدلی که شرط و فضای نهان از یکدیگر مستقل هستند را مدل پیشنهادی ۲ می‌نامیم. همچنین به منظور اختصار، AC0، AC1 و Total AC  به ترتیب، دقت رعایت شرط اول، رعایت شرط دوم و دقت کل رعایت شروط است و BL، SBL و JAC نیز به ترتیب نشان دهنده معیارهای
\bleu{}، \selfbleu{}
و \jaccard{} هستند.
\begin{table*}[!htb]
	\centering
	\caption{
		ارزیابی مدل‌های پایه و ارائه شده آموزش داده شده بر روی دادگان \lr{AmazonAppBook}، بر اساس معیار‌های مختلف}
	\label{table:amazon_result}
	\small\tabcolsep=0.07cm
	\begin{tabular}{||c||c c c|c c|c c|c c||}\hline\hline نام مدل & AC0                        & AC1                        & Total AC                   & BL2                        & BL5                        & SBL2                       & SBL5                       & JAC2                       & JAC5                       \\
		\hline\hline
		مدل پیشنهادی ۱
		                                               & $0.968$                    & $0.971$                    & $0.969$                    & $0.907$                    & $0.310$                    & $0.919$                    & $\cellcolor{gray!25}0.371$ & $\cellcolor{gray!25}0.651$ & $\cellcolor{gray!25}0.247$ \\
		\hline
		مدل پیشنهادی ۲
		                                               & $\cellcolor{gray!25}0.999$ & $\cellcolor{gray!25}0.999$ & $\cellcolor{gray!25}0.999$ & $\cellcolor{gray!25}0.943$ & $0.426$                    & $0.948$                    & $0.568$                    & $0.537$                    & $0.219$                    \\
		\hline
		\towardctg{}                                   & $0.983$                    & $0.980$                    & $0.982$                    & $0.928$                    & $\cellcolor{gray!25}0.444$ & $0.894$                    & $0.469$                    & $0.457$                    & $0.223$                    \\
		\hline
		\sentigan{}                                    & $0.991$                    & $0.996$                    & $0.994$                    & $0.903$                    & $0.422$                    & $\cellcolor{gray!25}0.892$ & $0.468$                    & $0.539$                    & $0.237$                    \\
		\hline
		\hline\end{tabular}\normalsize
\end{table*}

\begin{table*}[!htb]
	\centering
	\caption{
		ارزیابی مدل‌های پایه و ارائه شده آموزش داده شده بر روی دادگان \lr{YelpRestaurant}، بر اساس معیار‌های مختلف}
	\label{table:yelp_result}
	\small\tabcolsep=0.07cm
	\begin{tabular}{||c||c c c|c c|c c|c c||}\hline\hline نام مدل & AC0                        & AC1                        & Total AC                   & BL2                        & BL5                        & SBL2                       & SBL5                       & JAC2                       & JAC5                       \\
		\hline\hline
		مدل پیشنهادی ۱
		                                               & $0.810$                    & $0.964$                    & $0.887$                    & $0.686$                    & $0.155$                    & $\cellcolor{gray!25}0.753$ & $\cellcolor{gray!25}0.186$ & $0.462$                    & $0.102$                    \\
		\hline
		مدل پیشنهادی ۲
		                                               & $\cellcolor{gray!25}0.965$ & $\cellcolor{gray!25}0.991$ & $\cellcolor{gray!25}0.978$ & $0.799$                    & $0.231$                    & $0.868$                    & $0.351$                    & $0.416$                    & $0.116$                    \\
		\hline
		\towardctg{}                                   & $0.892$                    & $0.933$                    & $0.912$                    & $0.765$                    & $0.232$                    & $0.802$                    & $0.310$                    & $\cellcolor{gray!25}0.489$ & $\cellcolor{gray!25}0.141$ \\
		\hline
		\sentigan{}                                    & $0.942$                    & $0.987$                    & $0.965$                    & $\cellcolor{gray!25}0.807$ & $\cellcolor{gray!25}0.302$ & $0.834$                    & $0.467$                    & $0.338$                    & $0.093$                    \\
		\hline
		\hline\end{tabular}\normalsize
\end{table*}

همان طور که در جداول \ref{table:amazon_result} و \ref{table:yelp_result} مشخص است، عملکرد مدل پیشنهادی ۲ در رعایت شرط از سایر مدل‌ها بهتر است. در رعایت کیفیت و تنوع نیز نزدیک به مدل‌های پایه و یا بهتر عمل کرده است. لازم به ذکر است که مدل پیشنهادی ۲ تنها با یک مولد به درصد رعایت شرط بهتر از \sentigan{} دست یافته است.
\\
در مورد مدل پیشنهادی ۱ نیز، دقت رعایت شرط کمی عقب‌تر از مدل \towardctg{} بوده اما در رعایت ترکیب کیفیت و تنوع طبق معیار \jaccard{} در دادگان \amazon{} از سایر مدل‌ها با اختلاف زیاد بهتر عمل کرده است. این در حالیست که در دادگان \yelp{} عقب‌تر از \towardctg{} بوده اما همچنان موفق‌تر از \sentigan{} عمل می‌کند.
\\
\iffalse
	نکته قابل توجه و قابل بحث، اختلاف بیشتر درصد رعایت شرطِ مدل پیشنهادی از مدل \towardctg{} در دادگان \amazon{} است. علت این موضوع را شاید این طور بتوان جست‌وجو کرد که دادگان \amazon{} از دو موضوع تشکیل شده است؛ کتاب و برنامه. این دو موضوع چندان فضای مفهومی مشترکی ندارند؛ در حالی که دادگان \yelp{} همگی در مورد غذا و رستوران هستند. از این رو منطقی به نظر می‌رسد برای مدل اول فضای نهان $\bff{Z}$ تماما توسط شرط تعیین شود در حالی که در دادگان دیگر، مفاهیم و شرط می‌توانند مستقل از هم بوده و هر دو با هم یک جمله را تعیین کنند. مدل گرافی این دو دیدگاه در شکل \ref{fig:chap4:dataset_pgm} آمده است.
	\begin{figure}[h]
		\centering
		\begin{subfigure}{0.1\textheight}
			\centering
			\includegraphics[width=1.\textwidth]{images/pgm_disentangle.pdf}
			\caption{}
			\label{fig:chap4:dataset_pgm_d}
		\end{subfigure}
		\hspace{1cm}
		\begin{subfigure}{0.2\textheight}
			\centering
			\includegraphics[width=1.\textwidth]{images/pgm_hierarchical.pdf}
			\caption{}
			\label{fig:chap4:dataset_pgm_h}
		\end{subfigure}
		\caption{
			دو مدل گرافی متفاوتی که می‌توان برای یک \task{} شرطی در نظر گرفت.
			فضای نهان و شرط مستقل از هم
			(\subref{fig:chap4:dataset_pgm_d}، دادگان \yelp{})؛
			شرط به طور کامل فضای نهان را تعیین می‌کند
			(\subref{fig:chap4:dataset_pgm_h}، دادگان \amazon{}).
		}
		\label{fig:chap4:dataset_pgm}
	\end{figure}
	با در نظر گرفتن این توضیحات، به دلیل آنکه مدل \towardctg{} به نوعی استقلال بین شرط و فضای نهان $\bff{Z}$ را ایجاد می‌کند، چندان همخوانی با ذات دادگان \amazon{} نداشته و عملکرد ضعیف‌تری را از خود نشان می‌دهد.
\fi

\begin{table*}[!htb]
	\centering
	\caption{
		ارزیابی مدل‌های پایه و ارائه شده آموزش داده شده بر روی دادگان \lr{SST}، بر اساس معیار‌های مختلف}
	\label{table:mr15_result}
	\small\tabcolsep=0.07cm
	\begin{tabular}{||c||c c c|c c|c c|c c||}\hline\hline نام مدل & AC0                        & AC1                        & Total AC                   & BL2                        & BL5                        & SBL2                       & SBL5                       & JAC2                       & JAC5                       \\
		\hline\hline
		مدل پیشنهادی ۱
		                                               & $0.641$                    & $0.807$                    & $0.724$                    & $0.588$                    & $0.114$                    & $\cellcolor{gray!25}0.783$ & $\cellcolor{gray!25}0.238$ & $0.252$                    & $0.036$                    \\
		\hline
		مدل پیشنهادی ۲
		                                               & $0.797$                    & $0.873$                    & $0.835$                    & $0.553$                    & $0.104$                    & $0.805$                    & $0.296$                    & $0.224$                    & $0.028$                    \\
		\hline
		\towardctg{}                                   & $0.487$                    & $0.800$                    & $0.644$                    & $\cellcolor{gray!25}0.628$ & $\cellcolor{gray!25}0.171$ & $0.792$                    & $0.508$                    & $\cellcolor{gray!25}0.263$ & $\cellcolor{gray!25}0.045$ \\
		\hline
		\sentigan{}                                    & $\cellcolor{gray!25}0.827$ & $\cellcolor{gray!25}0.919$ & $\cellcolor{gray!25}0.873$ & $0.583$                    & $0.155$                    & $0.799$                    & $0.587$                    & $0.228$                    & $0.035$                    \\
		\hline
		\hline\end{tabular}\normalsize
\end{table*}


اما در مورد دادگان \sst{}، همان طور که در جدول \ref{table:mr15_result} مشخص است، هر دو مدل پیشنهادی به لحاظ رعایت شرط، از مدل \towardctg{} که به مانند دو مدل پیشنهادی مبتنی بر فضای نهان است، بهتر عمل می‌کنند. با این حال در رعایت معیار \jaccard{} نزدیک به مدل‌های پیشین هستند.
\\
در مورد دلیل عملکرد ضعیف‌تر مدل پیشنهادی و همچنین \towardctg{} در رعایت شرط که هر دو مدل مبتنی بر فضای نهان هستند، باید گفت که احتمالا به دلیل کم بودن و از سوی دیگر پیچیده بودن آن، فضای نهان معنای متناسب با جملات را در خود نداشته و توابع هزینه‌ای که مبتنی بر معنای فضای نهان هستند به درستی عمل نمی‌کنند. به نظر می‌رسد این موضوع در مدل پیشنهادی ۲، یا به دلیل عملکرد قوی‌تر معماری \transformer{} و یا اثر مثبت مستقل کردن فضای نهان از مقدار شرط و استفاده از یک \classifier{} در تطابق جمله تولیدی با شرط، این مدل از سایر مدل‌های مبتنی بر فضای نهان عملکرد بهتری داشته است. به طور کلی این طور می‌توان نتیجه‌گیری نمود که در صورت کم بودن داده‌ها، تا حد امکان از مدل‌های مبتنی بر فضای نهان استفاده نکرده و یا در طراحی آن دقت نمود. همان طور که در شکل \ref{fig:chap4:mr15} مشخص است، هم خطای بازسازی و هم خطای دسته‌بندی دادگان \validation{} بعد از مدتی شروع به افزایش می‌کند که نشان از
\trans{بیش‌برازش}{Overfit}
شدن مدل بر روی داده دارد. لازم به ذکر است، قطع کردن آموزش در نقطه کمینه منفی لگاریتم \likelihood{} نیز نتیجه مطلوبی ندارد.
\begin{figure}[h]
	\centering
	\begin{subfigure}{0.3\textheight}
		\centering
		\includegraphics[width=1.\textwidth]{images/figs2/2020_01_15__11_45_45__latent_classifier_cond_cls_loss.png}
		\caption{}
		\label{fig:chap4:mr15_cls}
	\end{subfigure}
	\begin{subfigure}{0.3\textheight}
		\centering
		\includegraphics[width=1.\textwidth]{images/figs2/2020_01_15__11_45_45__nll.png}
		\caption{}
		\label{fig:chap4:mr15_nll}
	\end{subfigure}
	\caption
	[نمودار‌های آموزش مولد شرطی بر روی دادگان \sst{}.]
	{
		نمودار‌های آموزش مولد شرطی بر روی دادگان \sst{}.
		هزینه دسته‌بندی بردار‌های فضای نهان بر روی دادگان \validation{}
		(\subref{fig:chap4:mr15_cls})؛
		خطای بازسازی دادگان \validation{}
		(\subref{fig:chap4:mr15_nll}).
	}
	\label{fig:chap4:mr15}
\end{figure}
\\
در مورد موفق‌تر بودن مدل \sentigan{} نیز این طور می‌توان گفت که این مدل به ازای هر شرط یک مدل مولد مجزا در نظر گرفته است؛ بنابراین هر مولد وظیفه یادگیری بخش مربوط به خود را دارد؛ به عبارت دیگر مسئله شرطی را به صورت مسئله غیر شرطی حل کرده است و بنابراین احتمال رعایت نکردن شرط بسیار کمتر خواهد بود. فارغ از این موضوع، این مدل با افزایش تعداد شرط‌ها با مشکل مواجه خواهد شد. با این وجود مدل پیشنهادی ۲ در دو مورد از داده‌ها عملکرد بهتری داشته است.
\\
نکته لازم به ذکر دیگر نیز نحوه نمونه‌برداری در مدل‌های مبتنی بر فضای نهان شامل دو مدل پیشنهادی و مدل \towardctg{} است. در مدل‌های پیشنهادی منبع تزریق عامل تصادفی تنها یک نقطه بوده و آن نیز نمونه‌برداری از فضای نهان است و از \greedydecoding{} در \decoder{} استفاده می‌شود. این در حالیست که در مدل \towardctg{} علاوه بر فضای نهان، در \decoder{} نیز با استفاده از پارامتر دمای $\tau$، کلمات نمونه‌برداری شده و عملا دو منبع تزریق عامل تصادفی در روند نمونه‌برداری وجود دارد که کنترل آن نیازمند دقت است.
\\
در مجموع این طور می‌توان جمع‌بندی نمود که مدل پیشنهادی ۱ با داشتن روند آموزشی نوین همچنان در سطح \towardctg{} عمل می‌کند اما مدل پیشنهادی ۲ در دقت رعایت شرط بسیار مطلوب و در رعایت کیفیت جملات نیز در سطح سایر مدل‌ها عمل کرده است. تعداد از نمودار‌های آموزش مدل‌های پیشنهادی ۱ و ۲ در پیوست \ref{app:figs} آمده است.

\iffalse
	\subsubsection{بررسی رفتار مولد شرطی}
	به منظور بررسی رفتار مولد شرطی، یک آزمایش ترتیب داده شد. همان طور که پیش‌تر توضیح داده شد، علت تقسیم کردن فضای نهان با توجه به مقادیر مختلف شرط، کم بودن ظرفیت مولد شرطی و ضعف آن در یادگیری هر توزیع پیچیده‌ای بود. در اینجا نیز عملکرد نسبتا مناسب آن در یک دسته و عکس آن در دسته دیگر می‌تواند احتمالا به این موضوع مرتبط باشد. به این منظور در تابع هزینه آموزش مولد شرطی تغییر کوچکی اعمال شد؛ به جای اینکه احتمال هر نمونه با شرط مرتبطش را در مولد شرطی بیشینه کنیم، احتمال همان نقاط اما با مقدار شرط دیگری را کمینه میکنیم. در واقع از نقاط با برچسب شرط نادرست به عنوان نمونه منفی بهره گرفته و انتظار داریم مولد شرطی به نمونه‌های منفی احتمال کم اما به نمونه‌های مثبت احتمال بالایی نسبت دهد. به صورت صوری تابع هزینه ذیل به تابع هزینه اصلی افزوده می‌شود:
	\begin{align}
		\mathcal{L'}_c (F) = & \lambda_\text{neg} \expected_{c' \sim p_{C'\neq c}, \bff{x} \sim p_\text{Data}(\bff{X}|c), \bff{z} \sim q(\bff{Z}|\bff{x})} [\log p_F(\bff{z}|c')]
	\end{align}
	و تابع هزینه کلی به صورت زیر بدست می‌آید:
	\begin{align}
		\mathcal{L}_c (F) = & - \expected_{\bff{x} \sim p_\text{Data}(\bff{X}|c), \bff{z} \sim q(\bff{Z}|\bff{x})} [\log p_F(\bff{z}|\bff{c})] +                                 \\
		                    & \lambda_\text{neg} \expected_{c' \sim p_{C'\neq c}, \bff{x} \sim p_\text{Data}(\bff{X}|c), \bff{z} \sim q(\bff{Z}|\bff{x})} [\log p_F(\bff{z}|c')]
	\end{align}
	\begin{figure}[h]
		\centering
		\begin{subfigure}[t]{0.3\textheight}
			\centering
			\includegraphics[width=1.\textwidth]{images/figs/2019_12_31__11_06_03__prior-flow-nll.png}
			\caption{}
			\label{fig:chap4:negprior_prior_nll}
		\end{subfigure}
		\begin{subfigure}[t]{0.3\textheight}
			\centering
			\includegraphics[width=1.\textwidth]{images/figs/2019_12_31__11_06_03__neg_prior-flow-nll.png}
			\caption{}
			\label{fig:chap4:negprior_negprior_nll}
		\end{subfigure}
		\caption{
			منفی لگاریتم \likelihood{} نمونه‌های مثبت (باید کمینه گردد)
			(\subref{fig:chap4:negprior_prior_nll}).
			منفی لگاریتم \likelihood{} نمونه‌های منفی (باید بیشینه گردد)
			(\subref{fig:chap4:negprior_negprior_nll}).
		}
		\label{fig:chap4:negprior}
	\end{figure}
	مطابق با شکل \ref{fig:chap4:negprior}، که نتیجه آموزش شبکه با توابع هزینه فوق با پارامتر
	$\lambda_\text{neg} = 0.05$
	است (با ضرایب بالاتر، آموزش ناپایدار می‌شد)، بر خلاف انتظارات، هر دو تابع با هم کمینه شدند. این موضوع به این معنی است که مدل مولد شرطی توانایی انتساب احتمال بالا به نمونه‌های مثبت و احتمال کم به نمونه‌های منفی را ندارد و یا هر دو کاهش می‌یابند و یا هر دو افزایش. از این مشاهده این طور می‌توان نتیجه‌گیری نمود که اعمال محدودیت تقسیم شده فضای نهان به مقادیر مختلف شرط، چندان کارساز نبوده و همچنان مولد شرطی توانایی تفکیک این دو دسته از یکدیگر را نداشته و احتمالا رفتار \meanseeking{} از خود بروز می‌دهد.
\fi