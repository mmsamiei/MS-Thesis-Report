\chapter{جمع‌بندی و کار‌های آتی}\label{Chap:Chap6}
\minitoc
در این پژوهش  جدیدترین کار‌های پیشین در حوزه‌ی تولید دنباله مورد بررسی قرار گرفت و  برخی از مزایا و معایب آنها بررسی شد. معیار‌هایی که روش‌های گذشته برای اثبات بهبودهای خود استفاده کرده‌اند، مورد نقد و بررسی قرار گرفت و مشاهده شد که  معیارهای مورد استفاده در برخی از روش‌ها، قضاوت ناعادلانه‌ای را انجام داده‌اند.
این مشکل  ریشه در ارزیابی کیفیت نمونه‌های تولیدی  بدون توجه به تنوع آنها دارد.
از این رو چند معیار جدید برای رفع این مشکل بیان و آزمایش‌هایی بر مبنای این معیارها انجام شد.
در آزمایش‌ها، کیفیت بالا و تنوع کم نتایج روش‌های مبتنی بر شبکه‌های مولد مقابله‌ای نشان داده شد و به این جمع‌بندی رسیدیم که روش‌های پیشین بر اساس یادگیری  مقابله‌ای در معیار‌هایی که همزمان کیفیت و تنوع را ارزیابی می‌کنند، پیشرفتی نسبت به روش پایه‌ی جبر معلم نداشته‌اند.
به علاوه ناپایداری این روش‌ها در آموزش نشان داده شد، این موضوع خود می‌تواند دلیلی بر نتایج نامناسب این دسته از روش‌ها باشد.


روش پیشنهادی با ایده‌ی آموزش  مولد توسط تمیزدهنده، بر مبنای تخمین نسبت چگالی دو توزیع معرفی و دو رویکرد برای این روش تشریح شد.
هم‌گرایی هر دو رویکرد به شکل نظری مورد بررسی قرار گرفت. هم‌چنین دیدیم که رویکرد اول در آزمایش‌ها نتایج بهتری نسبت به دیگر روش‌ها کسب کرد و نشان داد که آموزش پایداری دارد. از سوی دیگر، رویکرد دوم به صورت نظری دقیق‌تر بررسی شد و نشان داده شد که با در نظر گرفتن فرض سبکی برای تمیزدهنده، در هر گام مولد بهبود اتفاق می‌افتد.


برای کارهای آینده، در سه مسیر می‌توان پژوهش را ادامه داد.
\newline
مسیر اول، بررسی معیار‌های پیشنهادی و معیار‌های موجود است.
این بررسی‌ها می‌تواند شامل بررسی  مقاومت و حساسیت معیار  باشد. برای نمونه، نیاز به بررسی تغییر معیار در مقابل تخریب دنباله‌ها است. هم‌چنین حساسیت معیار به نحو و یا معنای دنباله‌ها و بخصوص دنباله‌های زبان طبیعی جای بررسی بیشتر دارد. هم‌چنین بررسی‌های دیگری مثل اثر طول دنباله بر معیارها نیازمند مطالعه است.
\newline
مسیر دوم، بررسی بیش‌تر روش پیشنهادی از نظر عملی است. اینکه چه ساختار‌هایی مناسب شبکه‌ی تمیزدهنده است و هم‌چنین نحوه‌ی تاثیر تابع
$f$
انتخابی در تابع هزینه (که در تحلیل نظری روش گفته شد) در عمل چگونه است. به‌علاوه تعمیم روش به حالتی که هدف، تولید دنباله‌هایی  به صورت شرطی باشد نیز می‌تواند مورد بررسی قرار بگیرد.
\newline
مسیر سوم، بهبود روش‌های پیشین است. زیرا در  این پژوهش با مشکلاتی در روش‌های پیشین مواجه شدیم که مورد توجه نبوده است. 
امید می‌رود که حل این مشکلات موجب بهبود روش‌های پیشین در حوزه باشد. برای مثال روش
\lr{SegGAN}
از جستجوی مونت کارلو برای تخمین امتیاز زیر دنباله‌ها استفاده می‌کند، انتظار داریم بتوان مشابه روش پیشنهادی، با شبکه‌ای بازگردنده این تخمین مستقیما محاسبه شود. به عنوان نمونه‌ای دیگر، متوجه شدیم که در روش‌های یادگیری مقابله‌ای با رویکرد تولید دنباله‌ی «توزیع کلمه» (بخش 
\ref{Ch2:Section:Method:SequenceOfDistribution})،
اُریبی وجود دارد. این اُریبی در تفاوت آموزش و آزمون است. زیرا این روش‌ها در آموزش توزیع را تولید می‌کنند ولی در آزمون از 
$\argmax$
توزیع تولیدی را برای تولید دنباله استفاده می‌کنند. امید می‌رود با استفاده از تکنیک‌های مشابه
\lr{Gumbel Softmax}
این اُریب رفع شود.


